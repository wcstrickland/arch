"use strict";
var __awaiter = (this && this.__awaiter) || function (thisArg, _arguments, P, generator) {
    function adopt(value) { return value instanceof P ? value : new P(function (resolve) { resolve(value); }); }
    return new (P || (P = Promise))(function (resolve, reject) {
        function fulfilled(value) { try { step(generator.next(value)); } catch (e) { reject(e); } }
        function rejected(value) { try { step(generator["throw"](value)); } catch (e) { reject(e); } }
        function step(result) { result.done ? resolve(result.value) : adopt(result.value).then(fulfilled, rejected); }
        step((generator = generator.apply(thisArg, _arguments || [])).next());
    });
};
var __asyncValues = (this && this.__asyncValues) || function (o) {
    if (!Symbol.asyncIterator) throw new TypeError("Symbol.asyncIterator is not defined.");
    var m = o[Symbol.asyncIterator], i;
    return m ? m.call(o) : (o = typeof __values === "function" ? __values(o) : o[Symbol.iterator](), i = {}, verb("next"), verb("throw"), verb("return"), i[Symbol.asyncIterator] = function () { return this; }, i);
    function verb(n) { i[n] = o[n] && function (v) { return new Promise(function (resolve, reject) { v = o[n](v), settle(resolve, reject, v.done, v.value); }); }; }
    function settle(resolve, reject, d, v) { Promise.resolve(v).then(function(v) { resolve({ value: v, done: d }); }, reject); }
};
Object.defineProperty(exports, "__esModule", { value: true });
exports.JsToXml = exports.ZipWriter = exports.StandardWriter = exports.ComponentWriter = exports.ComponentConverter = exports.ComponentReader = exports.pipeline = void 0;
/*
 * Copyright (c) 2020, salesforce.com, inc.
 * All rights reserved.
 * Licensed under the BSD 3-Clause license.
 * For full license text, see LICENSE.txt file in the repo root or https://opensource.org/licenses/BSD-3-Clause
 */
const archiver_1 = require("archiver");
const graceful_fs_1 = require("graceful-fs");
const path_1 = require("path");
const stream_1 = require("stream");
const util_1 = require("util");
const resolve_1 = require("../resolve");
const fileSystemHandler_1 = require("../utils/fileSystemHandler");
const common_1 = require("../common");
const convertContext_1 = require("./convertContext");
const transformers_1 = require("./transformers");
const fast_xml_parser_1 = require("fast-xml-parser");
const errors_1 = require("../errors");
const core_1 = require("@salesforce/core");
exports.pipeline = util_1.promisify(stream_1.pipeline);
class ComponentReader extends stream_1.Readable {
    constructor(components) {
        super({ objectMode: true });
        this.iter = this.createIterator(components);
    }
    _read() {
        let next = this.iter.next();
        while (!next.done) {
            this.push(next.value);
            next = this.iter.next();
        }
        this.push(null);
    }
    *createIterator(components) {
        for (const component of components) {
            yield component;
        }
    }
}
exports.ComponentReader = ComponentReader;
class ComponentConverter extends stream_1.Transform {
    constructor(targetFormat, registry, mergeSet, defaultDirectory) {
        super({ objectMode: true });
        this.context = new convertContext_1.ConvertContext();
        this.targetFormat = targetFormat;
        this.mergeSet = mergeSet;
        this.transformerFactory = new transformers_1.MetadataTransformerFactory(registry, this.context);
        this.defaultDirectory = defaultDirectory;
    }
    _transform(chunk, encoding, callback) {
        var _a;
        return __awaiter(this, void 0, void 0, function* () {
            let err;
            const writeInfos = [];
            // Only transform components not marked for delete.
            if (!chunk.isMarkedForDelete()) {
                try {
                    const converts = [];
                    const transformer = this.transformerFactory.getTransformer(chunk);
                    const mergeWith = (_a = this.mergeSet) === null || _a === void 0 ? void 0 : _a.getSourceComponents(chunk);
                    switch (this.targetFormat) {
                        case 'source':
                            if (mergeWith) {
                                for (const mergeComponent of mergeWith) {
                                    converts.push(transformer.toSourceFormat(chunk, mergeComponent));
                                }
                            }
                            if (converts.length === 0) {
                                converts.push(transformer.toSourceFormat(chunk));
                            }
                            break;
                        case 'metadata':
                            converts.push(transformer.toMetadataFormat(chunk));
                            break;
                        default:
                            throw new errors_1.LibraryError('error_convert_invalid_format', this.targetFormat);
                    }
                    // could maybe improve all this with lazy async collections...
                    (yield Promise.all(converts)).forEach((infos) => writeInfos.push(...infos));
                }
                catch (e) {
                    err = e;
                }
            }
            callback(err, { component: chunk, writeInfos });
        });
    }
    /**
     * Called at the end when all components have passed through the pipeline. Finalizers
     * take care of any additional work to be done at this stage e.g. recomposing child components.
     */
    _flush(callback) {
        var e_1, _a;
        return __awaiter(this, void 0, void 0, function* () {
            let err;
            try {
                try {
                    for (var _b = __asyncValues(this.context.executeFinalizers(this.defaultDirectory)), _c; _c = yield _b.next(), !_c.done;) {
                        const finalizerResult = _c.value;
                        finalizerResult.forEach((result) => this.push(result));
                    }
                }
                catch (e_1_1) { e_1 = { error: e_1_1 }; }
                finally {
                    try {
                        if (_c && !_c.done && (_a = _b.return)) yield _a.call(_b);
                    }
                    finally { if (e_1) throw e_1.error; }
                }
            }
            catch (e) {
                err = e;
            }
            callback(err);
        });
    }
}
exports.ComponentConverter = ComponentConverter;
class ComponentWriter extends stream_1.Writable {
    constructor(rootDestination) {
        super({ objectMode: true });
        this.forceIgnoredPaths = new Set();
        this.rootDestination = rootDestination;
    }
}
exports.ComponentWriter = ComponentWriter;
class StandardWriter extends ComponentWriter {
    constructor(rootDestination, resolver = new resolve_1.MetadataResolver()) {
        super(rootDestination);
        this.converted = [];
        this.resolver = resolver;
        this.logger = core_1.Logger.childFromRoot(this.constructor.name);
    }
    _write(chunk, encoding, callback) {
        return __awaiter(this, void 0, void 0, function* () {
            let err;
            if (chunk.writeInfos.length !== 0) {
                try {
                    const toResolve = [];
                    const writeTasks = chunk.writeInfos.map((info) => {
                        const fullDest = path_1.isAbsolute(info.output)
                            ? info.output
                            : path_1.join(this.rootDestination, info.output);
                        if (!graceful_fs_1.existsSync(fullDest)) {
                            for (const ignoredPath of this.forceIgnoredPaths) {
                                if (path_1.dirname(ignoredPath).includes(path_1.dirname(fullDest)) &&
                                    path_1.basename(ignoredPath).includes(path_1.basename(fullDest))) {
                                    return;
                                }
                            }
                        }
                        if (this.forceIgnoredPaths.has(fullDest)) {
                            return;
                        }
                        // if there are children, resolve each file. o/w just pick one of the files to resolve
                        if (toResolve.length === 0 || chunk.component.type.children) {
                            // This is a workaround for a server side ListViews bug where
                            // duplicate components are sent. W-9614275
                            if (toResolve.includes(fullDest)) {
                                this.logger.debug(`Ignoring duplicate metadata for: ${fullDest}`);
                                return;
                            }
                            toResolve.push(fullDest);
                        }
                        fileSystemHandler_1.ensureFileExists(fullDest);
                        return exports.pipeline(info.source, graceful_fs_1.createWriteStream(fullDest));
                    });
                    // it is a reasonable expectation that when a conversion call exits, the files of
                    // every component has been written to the destination. This await ensures the microtask
                    // queue is empty when that call exits and overall less memory is consumed.
                    yield Promise.all(writeTasks);
                    for (const fsPath of toResolve) {
                        this.converted.push(...this.resolver.getComponentsFromPath(fsPath));
                    }
                }
                catch (e) {
                    err = e;
                }
            }
            callback(err);
        });
    }
}
exports.StandardWriter = StandardWriter;
class ZipWriter extends ComponentWriter {
    constructor(rootDestination) {
        super(rootDestination);
        // compression-/speed+ (0)<---(3)---------->(9) compression+/speed-
        // 3 appears to be a decent balance of compression and speed. It felt like
        // higher values = diminishing returns on compression and made conversion slower
        this.zip = archiver_1.create('zip', { zlib: { level: 3 } });
        this.buffers = [];
        exports.pipeline(this.zip, this.getOutputStream());
    }
    _write(chunk, encoding, callback) {
        return __awaiter(this, void 0, void 0, function* () {
            let err;
            try {
                for (const info of chunk.writeInfos) {
                    this.addToZip(info.source, info.output);
                }
            }
            catch (e) {
                err = e;
            }
            callback(err);
        });
    }
    _final(callback) {
        return __awaiter(this, void 0, void 0, function* () {
            let err;
            try {
                yield this.zip.finalize();
            }
            catch (e) {
                err = e;
            }
            callback(err);
        });
    }
    addToZip(contents, path) {
        this.zip.append(contents, { name: path });
    }
    getOutputStream() {
        if (this.rootDestination) {
            return graceful_fs_1.createWriteStream(this.rootDestination);
        }
        else {
            const bufferWritable = new stream_1.Writable();
            bufferWritable._write = (chunk, encoding, cb) => {
                this.buffers.push(chunk);
                cb();
            };
            return bufferWritable;
        }
    }
    get buffer() {
        return Buffer.concat(this.buffers);
    }
}
exports.ZipWriter = ZipWriter;
/**
 * Convenient wrapper to serialize a js object to XML content. Implemented as a stream
 * to be used as a valid source for ComponentWriters in the conversion pipeline,
 * even though it's not beneficial in the typical way a stream is.
 */
class JsToXml extends stream_1.Readable {
    constructor(xmlObject) {
        super();
        this.xmlObject = xmlObject;
    }
    _read() {
        const js2Xml = new fast_xml_parser_1.j2xParser({ format: true, indentBy: '    ', ignoreAttributes: false });
        const xmlContent = common_1.XML_DECL.concat(js2Xml.parse(this.xmlObject));
        this.push(xmlContent);
        this.push(null);
    }
}
exports.JsToXml = JsToXml;
//# sourceMappingURL=streams.js.map